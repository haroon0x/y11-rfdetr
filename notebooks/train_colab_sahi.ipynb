{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Long-Range Person Detection - YOLOv11s with SAHI\n",
                "\n",
                "This notebook trains YOLOv11s on the VisDrone dataset **filtered for persons only**,\n",
                "and includes SAHI (Slicing Aided Hyper Inference) for enhanced small object detection.\n",
                "Optimized for Google Colab T4 GPU."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Clone the Repository\n",
                "!git clone https://github.com/haroon0x/y11-rfdetr.git\n",
                "%cd y11-rfdetr"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Install Dependencies\n",
                "!pip install -r requirements.txt\n",
                "!pip install ultralytics\n",
                "!pip install sahi  # SAHI for sliced inference"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Verify Environment\n",
                "import torch\n",
                "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Prepare VisDrone Dataset (Filter for Persons Only)\n",
                "!python scripts/prepare_visdrone.py"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Run Training Pipeline\n",
                "# Using YOLOv11s (Small) - optimized for Jetson Nano deployment\n",
                "!python scripts/train_pipeline.py --epochs 50 --batch 8 --imgsz 960 --workers 2 --model yolo11s.pt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. Display Training Results\n",
                "import os\n",
                "from IPython.display import Image, display\n",
                "\n",
                "base_dir = \"yolo11m_training_runs\"\n",
                "step_dir = \"step1_visdrone_person\"\n",
                "results_path = os.path.join(base_dir, step_dir, \"results.png\")\n",
                "confusion_matrix_path = os.path.join(base_dir, step_dir, \"confusion_matrix.png\")\n",
                "\n",
                "if os.path.exists(results_path):\n",
                "    print(\"Training Results:\")\n",
                "    display(Image(filename=results_path))\n",
                "if os.path.exists(confusion_matrix_path):\n",
                "    print(\"Confusion Matrix:\")\n",
                "    display(Image(filename=confusion_matrix_path))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 7. Benchmark Model\n",
                "!yolo benchmark model=yolo11m_training_runs/step1_visdrone_person/weights/best.pt data=data/visdrone_person/data.yaml imgsz=640 half=True device=0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 8. Run SAHI Inference (Example)\n",
                "# SAHI improves detection of small/distant persons by slicing the image\n",
                "!python scripts/inference_sahi.py --model yolo11m_training_runs/step1_visdrone_person/weights/best.pt --source data/visdrone_person/images/val/"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 9. Download Results\n",
                "!zip -r training_results.zip yolo11m_training_runs/step1_visdrone_person/ runs/sahi_inference/\n",
                "from google.colab import files\n",
                "files.download('training_results.zip')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}